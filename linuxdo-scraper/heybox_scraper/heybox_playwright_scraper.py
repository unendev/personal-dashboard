#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°é»‘ç›’Playwrightçˆ¬è™« - åŸºäºMCPæµ‹è¯•éªŒè¯çš„æ–¹æ¡ˆ
ä½¿ç”¨ Playwright æ— å¤´æµè§ˆå™¨ + x_xhh_tokenid è®¤è¯

ç‰ˆæœ¬ï¼šv2.3.0-personalized
æ›´æ–°æ—¶é—´ï¼š2025-01-11
æ›´æ–°å†…å®¹ï¼š
- âœ… æ”¯æŒè®¿é—®ä¸ªæ€§åŒ–é¦–é¡µï¼ˆç™»å½•åçš„ä¸ªæ€§åŒ–å†…å®¹ï¼Œåå‘æ¸¸æˆå¼€å‘ï¼‰
- âœ… å¢å¼ºç™»å½•çŠ¶æ€éªŒè¯ï¼ˆæ£€æŸ¥localStorageã€Cookieå’Œé¡µé¢å…ƒç´ ï¼‰
- âœ… åœ¨æµè§ˆå™¨ä¸Šä¸‹æ–‡åˆ›å»ºæ—¶é¢„å…ˆè®¾ç½®Cookieï¼Œç¡®ä¿é¦–æ¬¡è¯·æ±‚å³æºå¸¦è®¤è¯
- âœ… ä¼˜åŒ–ç­‰å¾…æœºåˆ¶ï¼Œä½¿ç”¨networkidleç¡®ä¿å¼‚æ­¥å†…å®¹å®Œå…¨åŠ è½½
- âœ… æ·»åŠ é‡è¯•æœºåˆ¶ï¼Œæœ€å¤šé‡è¯•3æ¬¡ç¡®ä¿ç™»å½•æˆåŠŸ
- âœ… ç§»é™¤playwright_stealthä¾èµ–ï¼ˆtokenè®¤è¯å·²è¶³å¤Ÿï¼Œé¿å…APIä¸ç¨³å®šï¼‰
- âœ… é€šç”¨é€‰æ‹©å™¨ï¼šä¸ä¾èµ–å…·ä½“classåï¼Œé€šè¿‡ç”¨æˆ·é“¾æ¥åå‘å®šä½
- âš ï¸ å…³é”®ä¿®å¤ï¼šè¯¦æƒ…é¡µTokenæ³¨å…¥ååˆ·æ–°é¡µé¢
- ğŸ”§ ä¼˜åŒ–è¯„è®ºæ•°é‡é™åˆ¶ä¸º10æ¡ï¼ˆå¯é…ç½®ï¼‰

æµ‹è¯•éªŒè¯ï¼š2025-01-11 âœ…
- Tokenè®¤è¯æˆåŠŸ
- ä¸ªæ€§åŒ–é¦–é¡µè®¿é—®æˆåŠŸ
- ç™»å½•çŠ¶æ€éªŒè¯æœ‰æ•ˆ
- é¡µé¢æ­£å¸¸åŠ è½½å¸–å­å†…å®¹
- MCPéªŒè¯é€šç”¨é€‰æ‹©å™¨æœ‰æ•ˆ

ä½¿ç”¨æ–¹æ³•ï¼š
  1. é…ç½® .env æ–‡ä»¶ä¸­çš„ HEYBOX_TOKEN_ID
  2. å®‰è£…Playwright: pip install playwright
  3. å®‰è£…æµè§ˆå™¨: python -m playwright install chromium
  4. è¿è¡Œ: python heybox_playwright_scraper.py
"""

# ç‰ˆæœ¬ä¿¡æ¯
__version__ = "v2.3.0-personalized"
__update_date__ = "2025-01-11"

import asyncio
import os
import json
import logging
import time
from datetime import datetime
from typing import List, Dict, Any
from playwright.async_api import async_playwright, Page
# from playwright_stealth import stealth  # å·²ç¦ç”¨ï¼štokenè®¤è¯å·²è¶³å¤Ÿ
import asyncpg
import re

# å¯¼å…¥é…ç½®
from config import (
    HEYBOX_TOKEN_ID, HEYBOX_USER_PKEY, HEYBOX_HOME_URL,
    POST_LIMIT, COMMENT_LIMIT, REQUEST_INTERVAL,
    MAX_RETRIES, RETRY_DELAY, AI_REQUEST_DELAY,
    DEEPSEEK_API_KEY, DEEPSEEK_API_URL,
    DATABASE_URL, USE_PROXY, get_proxies, check_config
)

# ========== æ—¥å¿—é…ç½® ==========
os.makedirs('logs', exist_ok=True)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler('logs/heybox_scraper.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ========== æµè§ˆå™¨åˆå§‹åŒ– ==========

async def verify_login_status(page: Page) -> bool:
    """
    éªŒè¯é¡µé¢ç™»å½•çŠ¶æ€
    
    é€šè¿‡æ£€æŸ¥localStorageã€Cookieå’Œé¡µé¢å…ƒç´ åˆ¤æ–­æ˜¯å¦å·²ç™»å½•
    """
    try:
        # æ£€æŸ¥localStorageä¸­çš„token
        token_in_storage = await page.evaluate("""
            () => {
                return localStorage.getItem('x_xhh_tokenid') !== null;
            }
        """)
        
        # æ£€æŸ¥Cookieä¸­çš„token
        cookies = await page.context.cookies()
        token_in_cookie = any(
            cookie.get('name') == 'x_xhh_tokenid' and cookie.get('value')
            for cookie in cookies
        )
        
        # æ£€æŸ¥é¡µé¢æ˜¯å¦æœ‰ç™»å½•æ ‡è¯†ï¼ˆç”¨æˆ·å¤´åƒã€ç”¨æˆ·åç­‰ï¼‰
        has_user_info = await page.evaluate("""
            () => {
                // æ£€æŸ¥æ˜¯å¦æœ‰ç”¨æˆ·ç›¸å…³å…ƒç´ ï¼ˆå¤´åƒã€ç”¨æˆ·åç­‰ï¼‰
                const userLinks = document.querySelectorAll('a[href*="/app/user/profile/"]');
                const hasAvatar = document.querySelector('img[src*="avatar"], img[alt*="å¤´åƒ"]');
                return userLinks.length > 0 || hasAvatar !== null;
            }
        """)
        
        # æ›´çµæ´»çš„ç™»å½•åˆ¤æ–­ï¼šCookieæœ‰Tokenä¸”é¡µé¢æœ‰ç”¨æˆ·ä¿¡æ¯å³å¯ï¼ˆlocalStorageå¯èƒ½å› åˆ·æ–°ä¸¢å¤±ï¼‰
        is_logged_in = token_in_cookie and has_user_info
        
        logger.info(f"  ğŸ” ç™»å½•çŠ¶æ€æ£€æµ‹:")
        logger.info(f"    - localStorageæœ‰Token: {token_in_storage}")
        logger.info(f"    - Cookieæœ‰Token: {token_in_cookie}")
        logger.info(f"    - é¡µé¢æœ‰ç”¨æˆ·ä¿¡æ¯: {has_user_info}")
        logger.info(f"    - ç»¼åˆåˆ¤æ–­: {'âœ… å·²ç™»å½•' if is_logged_in else 'âŒ æœªç™»å½•'}")
        
        # å¦‚æœCookieå’Œé¡µé¢ä¿¡æ¯éƒ½æ»¡è¶³ï¼Œä½†localStorageæ²¡æœ‰ï¼Œå°è¯•é‡æ–°æ³¨å…¥
        if is_logged_in and not token_in_storage:
            logger.info("  ğŸ”§ æ£€æµ‹åˆ°localStorageç¼ºå°‘Tokenï¼Œé‡æ–°æ³¨å…¥...")
            try:
                user_pkey = HEYBOX_USER_PKEY if HEYBOX_USER_PKEY else ""
                await page.evaluate(f"""
                    () => {{
                        const token = "{HEYBOX_TOKEN_ID}";
                        const userPkey = "{user_pkey}";
                        localStorage.setItem('x_xhh_tokenid', token);
                        sessionStorage.setItem('x_xhh_tokenid', token);
                        if (userPkey) {{
                            document.cookie = `user_pkey=${{userPkey}}; path=/; domain=.xiaoheihe.cn`;
                        }}
                    }}
                """)
                logger.info("  âœ“ localStorage Tokenå·²é‡æ–°æ³¨å…¥")
            except Exception as e:
                logger.warning(f"  âš  é‡æ–°æ³¨å…¥Tokenå¤±è´¥: {e}")
        
        return is_logged_in
        
    except Exception as e:
        logger.warning(f"  âš  ç™»å½•çŠ¶æ€æ£€æµ‹å¤±è´¥: {e}")
        return False

async def init_browser_with_token(page: Page, token: str, max_retries: int = 3):
    """
    åˆå§‹åŒ–æµè§ˆå™¨å¹¶æ³¨å…¥Tokenï¼Œç¡®ä¿è®¿é—®ä¸ªæ€§åŒ–é¦–é¡µ
    
    åŸºäºMCPæµ‹è¯•éªŒè¯çš„æ–¹æ³•ï¼š
    1. è®¿é—®é¦–é¡µ
    2. æ³¨å…¥tokenåˆ°localStorageã€sessionStorageå’Œcookie
    3. éªŒè¯ç™»å½•çŠ¶æ€
    4. ç¡®ä¿ä¸ªæ€§åŒ–å†…å®¹åŠ è½½å®Œæˆ
    """
    logger.info(f"ğŸŒ è®¿é—®é¦–é¡µ: {HEYBOX_HOME_URL}")
    
    for attempt in range(max_retries):
        try:
            # è®¿é—®é¦–é¡µï¼ˆé¦–æ¬¡è®¿é—®æ—¶Cookieå·²åœ¨ä¸Šä¸‹æ–‡åˆ›å»ºæ—¶è®¾ç½®ï¼‰
            await page.goto(HEYBOX_HOME_URL, wait_until='networkidle', timeout=60000)
            logger.info("  âœ“ é¡µé¢åŠ è½½å®Œæˆ")
            
            # æ³¨å…¥tokenå’Œuser_pkeyï¼ˆç¡®ä¿æ‰€æœ‰å­˜å‚¨ä½ç½®éƒ½æœ‰ï¼‰
            user_pkey = HEYBOX_USER_PKEY if HEYBOX_USER_PKEY else ""
            await page.evaluate(f"""
                () => {{
                    const token = "{token}";
                    const userPkey = "{user_pkey}";
                    localStorage.setItem('x_xhh_tokenid', token);
                    sessionStorage.setItem('x_xhh_tokenid', token);
                    document.cookie = `x_xhh_tokenid=${{token}}; path=/; domain=.xiaoheihe.cn`;
                    if (userPkey) {{
                        document.cookie = `user_pkey=${{userPkey}}; path=/; domain=.xiaoheihe.cn`;
                    }}
                }}
            """)
            logger.info("  âœ“ Tokenæ³¨å…¥æˆåŠŸ")
            
            # ç­‰å¾…ä¸€ä¸‹è®©é¡µé¢ååº”
            await asyncio.sleep(2)
            
            # åˆ·æ–°é¡µé¢ä½¿tokenç”Ÿæ•ˆï¼Œç­‰å¾…ç½‘ç»œè¯·æ±‚å®Œæˆ
            await page.reload(wait_until='networkidle', timeout=60000)
            logger.info("  âœ“ é¡µé¢åˆ·æ–°ï¼ŒTokenå·²æ¿€æ´»")
            
            # ç­‰å¾…ä¸ªæ€§åŒ–å†…å®¹åŠ è½½ï¼ˆæ¸¸æˆæ¨èã€å…³æ³¨å†…å®¹ç­‰ï¼‰
            # ä¸ªæ€§åŒ–æ¨èAPIå¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´
            logger.info("  â³ ç­‰å¾…ä¸ªæ€§åŒ–å†…å®¹åŠ è½½...")
            await asyncio.sleep(8)  # å¢åŠ ç­‰å¾…æ—¶é—´ï¼Œç¡®ä¿ä¸ªæ€§åŒ–APIè¯·æ±‚å®Œæˆ
            
            # å¤šæ¬¡æ»šåŠ¨è§¦å‘æ‡’åŠ è½½ï¼Œç¡®ä¿ä¸ªæ€§åŒ–å†…å®¹å®Œå…¨åŠ è½½
            for scroll_step in range(3):
                await page.evaluate(f"""
                    () => {{
                        window.scrollTo(0, document.body.scrollHeight * {scroll_step + 1} / 4);
                    }}
                """)
                await asyncio.sleep(2)  # æ¯æ¬¡æ»šåŠ¨åç­‰å¾…å†…å®¹åŠ è½½
                logger.info(f"  ğŸ“œ æ»šåŠ¨åŠ è½½ ({scroll_step + 1}/3)")
            
            # æ»šåŠ¨å›é¡¶éƒ¨ï¼Œå‡†å¤‡æå–æ•°æ®
            await page.evaluate("() => { window.scrollTo(0, 0); }")
            await asyncio.sleep(2)
            
            # éªŒè¯Cookieæ˜¯å¦æ­£ç¡®è®¾ç½®
            cookies = await page.context.cookies()
            has_token = any(c.get('name') == 'x_xhh_tokenid' for c in cookies)
            has_pkey = any(c.get('name') == 'user_pkey' for c in cookies)
            logger.info(f"  ğŸ” CookieéªŒè¯: x_xhh_tokenid={has_token}, user_pkey={has_pkey}")
            
            # éªŒè¯ç™»å½•çŠ¶æ€
            is_logged_in = await verify_login_status(page)
            
            if is_logged_in:
                logger.info("  âœ… æˆåŠŸè®¿é—®ä¸ªæ€§åŒ–é¦–é¡µï¼ˆå·²ç™»å½•çŠ¶æ€ï¼‰")
                return True
            else:
                if attempt < max_retries - 1:
                    logger.warning(f"  âš  ç™»å½•çŠ¶æ€éªŒè¯å¤±è´¥ï¼Œé‡è¯• {attempt + 1}/{max_retries}")
                    await asyncio.sleep(3)
                    continue
                else:
                    logger.error("  âŒ ç™»å½•çŠ¶æ€éªŒè¯å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
                    logger.warning("  ğŸ’¡ æç¤ºï¼šè¯·æ£€æŸ¥Tokenæ˜¯å¦æœ‰æ•ˆï¼Œæˆ–æ‰‹åŠ¨éªŒè¯ç™»å½•çŠ¶æ€")
                    return False
            
        except Exception as e:
            if attempt < max_retries - 1:
                logger.warning(f"  âš  åˆå§‹åŒ–å¤±è´¥ï¼ˆå°è¯• {attempt + 1}/{max_retries}ï¼‰: {e}")
                await asyncio.sleep(3)
                continue
            else:
                logger.error(f"  âœ— åˆå§‹åŒ–å¤±è´¥: {e}")
                return False
    
    return False

# ========== æ•°æ®æå– ==========

async def extract_posts_from_page(page: Page, limit: int = POST_LIMIT, label: str = "") -> List[Dict]:
    """
    ä»é¡µé¢æå–å¸–å­æ•°æ®
    
    åŸºäºé¡µé¢å®é™…ç»“æ„æå–ï¼ˆMCPæµ‹è¯•ä¸­è§‚å¯Ÿåˆ°çš„ï¼‰
    
    Args:
        page: Playwrighté¡µé¢å¯¹è±¡
        limit: æå–å¸–å­æ•°é‡é™åˆ¶
        label: æ ‡ç­¾ï¼ˆç”¨äºåŒºåˆ†ä¸åŒæ¥æºï¼Œå¦‚"é€šç”¨é¦–é¡µ"ã€"ä¸ªæ€§åŒ–é¦–é¡µ"ï¼‰
    """
    prefix = f"[{label}] " if label else ""
    logger.info(f"{prefix}ğŸ“ å¼€å§‹æå–å¸–å­æ•°æ®ï¼ˆç›®æ ‡{limit}æ¡ï¼‰...")
    
    try:
        # è·å–é¡µé¢HTML
        content = await page.content()
        
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–linkæ•°æ®ï¼ˆä»hrefä¸­æå–IDï¼‰
        post_ids = re.findall(r'/app/bbs/link/(\d+)\?', content)
        logger.info(f"{prefix}  æ‰¾åˆ° {len(post_ids)} ä¸ªå¸–å­ID")
        
        # è·å–é¡µé¢çš„çº¯æ–‡æœ¬å†…å®¹ç”¨äºæå–
        posts_data = await page.evaluate("""
            () => {
                const posts = [];
                const links = document.querySelectorAll('a[href*="/app/bbs/link/"]');
                
                links.forEach((link, index) => {
                    if (index >= 20) return;
                    
                    const href = link.href || link.getAttribute('href');
                    const fullText = link.textContent || '';
                    
                    if (href && fullText) {
                        posts.push({
                            href: href,
                            text: fullText.trim()
                        });
                    }
                });
                
                return posts;
            }
        """)
        
        logger.info(f"{prefix}  æå–åˆ° {len(posts_data)} ä¸ªå¸–å­çš„åŸå§‹æ•°æ®")
        
        # è§£ææå–çš„æ•°æ®
        posts = []
        for item in posts_data[:limit]:
            try:
                # æå–ID
                id_match = re.search(r'/link/(\d+)', item['href'])
                if not id_match:
                    continue
                
                post_id = id_match.group(1)
                text = item['text']
                
                # æ”¹è¿›çš„æ–‡æœ¬è§£æé€»è¾‘
                # æ ¼å¼åˆ†æï¼šä½œè€…å Lv.ç­‰çº§ æ ‡é¢˜æˆ–å†…å®¹ æ•°å­—(ç‚¹èµ/è¯„è®º)...
                
                # 1. æå–ä½œè€…å’Œç­‰çº§ï¼ˆæ ¼å¼ï¼šä½œè€…å Lv.æ•°å­—ï¼‰
                author_match = re.match(r'^(.+?)\s+Lv\.(\d+)\s*(.*)$', text)
                
                if author_match:
                    author = author_match.group(1).strip()
                    level = author_match.group(2)
                    remaining_text = author_match.group(3)
                else:
                    author = ''
                    remaining_text = text
                
                # 2. æå–æ ‡é¢˜ï¼ˆå‰©ä½™æ–‡æœ¬çš„å‰200ä¸ªå­—ç¬¦ä½œä¸ºæ ‡é¢˜ï¼‰
                title = remaining_text[:200].strip() if remaining_text else ''
                
                # 3. æå–æ‰€æœ‰æ•°å­—ï¼ˆç”¨äºç‚¹èµæ•°ã€è¯„è®ºæ•°ã€æ•°æ®ç­‰ï¼‰
                numbers = re.findall(r'\b(\d+)\b', text)
                
                # 4. æ™ºèƒ½è§£ææ•°å­—ï¼ˆå‡è®¾æœ€åä¸¤ä¸ªæ•°å­—é€šå¸¸æ˜¯ç‚¹èµå’Œè¯„è®ºï¼‰
                likes = 0
                comments = 0
                
                if len(numbers) >= 2:
                    try:
                        # æœ€åä¸€ä¸ªé€šå¸¸æ˜¯è¯„è®ºæ•°
                        comments = int(numbers[-1])
                        # å€’æ•°ç¬¬äºŒä¸ªé€šå¸¸æ˜¯ç‚¹èµæ•°
                        likes = int(numbers[-2])
                    except (ValueError, IndexError):
                        pass
                elif len(numbers) == 1:
                    try:
                        # åªæœ‰ä¸€ä¸ªæ•°å­—æ—¶å½“ä½œè¯„è®ºæ•°
                        comments = int(numbers[0])
                    except ValueError:
                        pass
                
                # åªæœ‰åœ¨æå–åˆ°æœ‰æ•ˆæ•°æ®æ—¶æ‰æ·»åŠ å¸–å­
                if title:  # ç¡®ä¿è‡³å°‘æœ‰æ ‡é¢˜
                    post = {
                        'id': post_id,
                        'title': title,
                        'summary': title[:100],  # æ‘˜è¦ä¸ºæ ‡é¢˜å‰100å­—
                        'author': author,
                        'url': item['href'],
                        'likes_count': likes,
                        'comments_count': comments,
                        'created_time': int(time.time())
                    }
                    
                    posts.append(post)
                    logger.debug(f"    [{len(posts)}] ä½œè€…:{author} | ç‚¹èµ:{likes} è¯„è®º:{comments} | {title[:40]}...")
                else:
                    logger.debug(f"    âš  è·³è¿‡ç©ºæ ‡é¢˜çš„å¸–å­")
                
            except Exception as e:
                logger.warning(f"    è§£æå¸–å­å¤±è´¥: {e}")
                logger.debug(f"    åŸå§‹æ–‡æœ¬: {text[:100]}")
                continue
        
        logger.info(f"{prefix}âœ… æˆåŠŸæå– {len(posts)} ä¸ªå¸–å­")
        return posts
        
    except Exception as e:
        logger.error(f"âŒ æå–å¤±è´¥: {e}")
        return []

async def extract_comments(page: Page, post_id: str, post_url: str) -> List[Dict]:
    """æå–å¸–å­è¯„è®º - MCPè°ƒè¯•éªŒè¯ç‰ˆæœ¬"""
    logger.info(f"  ğŸ’¬ æŠ“å–è¯„è®º: {post_id}")
    logger.info(f"     ğŸ“ URL: {post_url}")
    
    try:
        # è®¿é—®å¸–å­è¯¦æƒ…é¡µ
        await page.goto(post_url, wait_until='domcontentloaded', timeout=30000)
        
        # ç¡®ä¿Tokenå’Œuser_pkeyåœ¨è¯¦æƒ…é¡µä¹Ÿæœ‰æ•ˆï¼ˆé˜²æ­¢cookieä½œç”¨åŸŸé—®é¢˜ï¼‰
        user_pkey = HEYBOX_USER_PKEY if HEYBOX_USER_PKEY else ""
        await page.evaluate(f"""
            () => {{
                const token = "{HEYBOX_TOKEN_ID}";
                const userPkey = "{user_pkey}";
                localStorage.setItem('x_xhh_tokenid', token);
                sessionStorage.setItem('x_xhh_tokenid', token);
                document.cookie = `x_xhh_tokenid=${{token}}; path=/; domain=.xiaoheihe.cn`;
                if (userPkey) {{
                    document.cookie = `user_pkey=${{userPkey}}; path=/; domain=.xiaoheihe.cn`;
                }}
            }}
        """)
        
        # âš ï¸ å…³é”®ï¼šåˆ·æ–°é¡µé¢ä½¿Tokenç”Ÿæ•ˆï¼ˆMCPè°ƒè¯•éªŒè¯å¿…é¡»æ­¥éª¤ï¼‰
        await page.reload(wait_until='domcontentloaded')
        await asyncio.sleep(3)  # ç­‰å¾…è¯„è®ºåŠ è½½
        
        # å°è¯•æ»šåŠ¨åŠ è½½æ›´å¤šè¯„è®º
        await page.evaluate("""
            () => {
                window.scrollTo(0, document.body.scrollHeight / 2);
            }
        """)
        await asyncio.sleep(1)
        
        # è°ƒè¯•ï¼šæ£€æŸ¥é¡µé¢ç»“æ„
        page_info = await page.evaluate("""
            () => {
                const commentSection = document.querySelector('.link-comment');
                const commentItems = document.querySelectorAll('.link-comment__comment-item');
                return {
                    hasCommentSection: !!commentSection,
                    commentItemsCount: commentItems.length,
                    pageTitle: document.title
                };
            }
        """)
        logger.info(f"     ğŸ” é¡µé¢æ£€æµ‹: è¯„è®ºåŒº={page_info['hasCommentSection']}, è¯„è®ºé¡¹æ•°={page_info['commentItemsCount']}")
        
        # æå–è¯„è®ºæ•°æ® - é€šç”¨æ–¹æ³•ï¼ˆä¸ä¾èµ–å…·ä½“classï¼‰
        comments_data = await page.evaluate(f"""
            () => {{
                const comments = [];
                const limit = {COMMENT_LIMIT};
                
                // æ‰¾æ‰€æœ‰ç”¨æˆ·é“¾æ¥ï¼ˆè¯„è®ºå¿…æœ‰ä½œè€…é“¾æ¥ï¼‰
                const allLinks = document.querySelectorAll('a[href*="/app/user/profile/"]');
                const processedContainers = new Set();
                
                for (const link of allLinks) {{
                    if (comments.length >= limit) break;
                    
                    // æ‰¾æœ€è¿‘çš„è¯„è®ºå®¹å™¨
                    let container = link.closest('div[class*="comment"]') || link.parentElement?.parentElement;
                    if (!container || processedContainers.has(container)) continue;
                    processedContainers.add(container);
                    
                    // æå–ä½œè€…
                    const author = link.textContent.trim().split('\\n')[0].replace(/ä½œè€…|Lv\\.\\d+/g, '').trim();
                    
                    // æå–è¯„è®ºå†…å®¹ï¼ˆæ‰¾æœ€é•¿æ–‡æœ¬ï¼‰
                    let content = '';
                    const textDivs = container.querySelectorAll('div, p, span');
                    for (const div of textDivs) {{
                        const text = div.textContent.trim();
                        if (text.length > Math.max(20, content.length) && 
                            !text.includes('å°æ—¶å‰') && !text.includes('å¤©å‰') &&
                            !text.includes('Lv.') && !text.includes('å›å¤')) {{
                            content = text.substring(0, 200);
                        }}
                    }}
                    
                    // æå–ç‚¹èµæ•°
                    const buttons = Array.from(container.querySelectorAll('button'));
                    const likeBtn = buttons.find(b => /^\\s*\\d+\\s*$/.test(b.textContent.trim()));
                    const likes = likeBtn ? parseInt(likeBtn.textContent.trim()) : 0;
                    
                    if (author && content.length > 10) {{
                        comments.push({{
                            id: `comment_{post_id}_${{comments.length}}`,
                            author: author,
                            content: content,
                            likes_count: likes,
                            created_at: 'æœ€è¿‘'
                        }});
                    }}
                }}
                
                return comments;
            }}
        """)
        
        logger.info(f"    âœ“ è·å–åˆ° {len(comments_data)} æ¡è¯„è®º")
        return comments_data
        
    except Exception as e:
        logger.warning(f"    âœ— è¯„è®ºæŠ“å–å¤±è´¥: {e}")
        return []

# ========== AIåˆ†æ ==========

def analyze_with_ai(post: Dict, comments: List[Dict]) -> Dict:
    """ä½¿ç”¨DeepSeek AIåˆ†æ - å¯¹æ ‡Redditçš„é«˜è´¨é‡åˆ†æ"""
    logger.info(f"  ğŸ¤– AIåˆ†æ: {post['title'][:30]}...")
    
    if not DEEPSEEK_API_KEY:
        return {
            'title_cn': post.get('title', ''),
            'core_issue': post.get('summary', '')[:100],
            'key_info': [post['title']],
            'post_type': 'æœªåˆ†ç±»',
            'value_assessment': 'ä¸­',
            'detailed_analysis': ''
        }
    
    import requests
    
    # æ„å»ºå†…å®¹æ‘˜è¦
    excerpt = post.get('summary', '')[:1000]
    if not excerpt.strip():
        excerpt = "ï¼ˆæ— è¯¦ç»†å†…å®¹ï¼‰"
    
    # æ„å»ºè¯„è®ºåŒºç²¾åï¼ˆå¯¹æ ‡Reddit - é«˜èµå‰3æ¡ï¼‰
    comment_section = ""
    if comments and len(comments) > 0:
        # æŒ‰ç‚¹èµæ•°æ’åºï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        sorted_comments = sorted(comments, key=lambda x: x.get('likes_count', 0), reverse=True)
        top_comments = sorted_comments[:3]
        
        comment_section = "\n\n**ç¤¾åŒºè®¨è®ºç²¾å**ï¼ˆé«˜èµè¯„è®ºï¼‰ï¼š\n"
        for i, comment in enumerate(top_comments, 1):
            comment_body = comment.get('content', '')[:200]
            likes = comment.get('likes_count', 0)
            author = comment.get('author', 'åŒ¿å')
            comment_section += f"{i}. [{author}] (ğŸ‘{likes}): {comment_body}...\n"
        logger.info(f"  âœ“ åŒ…å« {len(top_comments)} æ¡é«˜èµè¯„è®ºåˆ°åˆ†æ")
    else:
        num_comments = post.get('comments_count', 0)
        if num_comments > 0:
            comment_section = f"\n\n**æ³¨æ„**ï¼šè¯¥å¸–å­æœ‰ {num_comments} æ¡è¯„è®ºï¼Œä½†è¯„è®ºå†…å®¹æœªåŒ…å«åœ¨æœ¬æ¬¡åˆ†æä¸­ã€‚è¯·ä»…åŸºäºå¸–å­æ ‡é¢˜å’Œæ­£æ–‡å†…å®¹è¿›è¡Œåˆ†æï¼Œä¸è¦æ¨æµ‹è¯„è®ºåŒºå†…å®¹ã€‚"
            logger.info(f"  âš  å¸–å­æœ‰ {num_comments} æ¡è¯„è®ºä½†æœªè·å–")
        else:
            logger.info(f"  â„¹ è¯¥å¸–å­æ— è¯„è®º")
    
    # æ„å»ºé«˜è´¨é‡Promptï¼ˆå¯¹æ ‡Redditï¼Œé€‚é…æ¸¸æˆç¤¾åŒºï¼‰
    prompt = f"""
ä½ æ˜¯ä¸“ä¸šçš„æ¸¸æˆç¤¾åŒºå†…å®¹åˆ†æä¸“å®¶ï¼Œæ“…é•¿åˆ†æå°é»‘ç›’ç­‰æ¸¸æˆå¹³å°çš„å¸–å­å’Œç¤¾åŒºè®¨è®ºã€‚è¯·åˆ†æä»¥ä¸‹å¸–å­ï¼ˆå«ç¤¾åŒºè®¨è®ºï¼‰ï¼Œç”Ÿæˆä¸“ä¸šåˆ†ææŠ¥å‘Šã€‚

**åŸå§‹å¸–å­ä¿¡æ¯**ï¼š
- æ ‡é¢˜: {post['title']}
- ä½œè€…: {post['author']}
- æ¸¸æˆæ ‡ç­¾: {post.get('game_tag', 'æœªçŸ¥')}
- å†…å®¹: {excerpt}{comment_section}
- äº’åŠ¨æ•°æ®: {post['likes_count']}èµ / {post['comments_count']}è¯„è®º

**è¯·ä¸¥æ ¼æŒ‰JSONæ ¼å¼è¾“å‡ºï¼ˆä¸è¦åŒ…å«```json```æ ‡è®°ï¼‰**ï¼š
{{
  "title_cn": "ä¸­æ–‡ä¼˜åŒ–æ ‡é¢˜ï¼ˆå¦‚æœåŸæ ‡é¢˜å·²æ˜¯ä¸­æ–‡ï¼Œå¯ä¼˜åŒ–ä½¿å…¶æ›´ç®€æ´ä¸“ä¸šï¼›å¦‚æœæ˜¯è‹±æ–‡æˆ–æ··æ‚ï¼Œç¿»è¯‘ä¸ºä¸­æ–‡ï¼‰",
  "core_issue": "æ ¸å¿ƒè®®é¢˜ï¼ˆä¸€å¥è¯æ¦‚æ‹¬ï¼‰",
  "key_info": ["å…³é”®ä¿¡æ¯1", "å…³é”®ä¿¡æ¯2", "å…³é”®ä¿¡æ¯3"],
  "post_type": "ä»[æ¸¸æˆæ”»ç•¥, æ–°é—»èµ„è®¯, ç©å®¶è®¨è®º, ç¡¬ä»¶è¯„æµ‹, é—®é¢˜æ±‚åŠ©, èµ„æºåˆ†äº«, è§†é¢‘å†…å®¹, å…¶ä»–]é€‰ä¸€ä¸ª",
  "value_assessment": "ä»[é«˜, ä¸­, ä½]é€‰ä¸€ä¸ª",
  "detailed_analysis": "ç”Ÿæˆ600-1200å­—ä¸“ä¸šåˆ†æï¼Œmarkdownæ ¼å¼ï¼Œå¿…é¡»åŒ…å«ä»¥ä¸‹6ä¸ªç»´åº¦ï¼š\\n\\n## ğŸ® å†…å®¹èƒŒæ™¯\\nï¼ˆä»‹ç»å¸–å­çš„æ¸¸æˆ/ç¡¬ä»¶èƒŒæ™¯ã€å‘å¸ƒæ—¶æœºã€ç¤¾åŒºå…³æ³¨åº¦ï¼‰\\n\\n## ğŸ’¡ æ ¸å¿ƒå†…å®¹\\nï¼ˆæç‚¼å¸–å­çš„ä¸»è¦ä¿¡æ¯ã€å…³é”®è§‚ç‚¹æˆ–æ”»ç•¥è¦ç‚¹ï¼‰\\n\\n## ğŸ› ï¸ å®ç”¨ä»·å€¼\\nï¼ˆåˆ†æå¯¹ç©å®¶çš„å®é™…å¸®åŠ©ã€å¯æ“ä½œæ€§ã€é€‚ç”¨åœºæ™¯ï¼‰\\n\\n## ğŸ’¬ ç¤¾åŒºåå“\\nï¼ˆåŸºäºè¯„è®ºåˆ†æç©å®¶åé¦ˆã€äº‰è®®ç‚¹ã€å…±è¯†è§‚ç‚¹ï¼‰\\n\\n## ğŸ“š å‚è€ƒä»·å€¼\\nï¼ˆå¯¹å…¶ä»–ç©å®¶çš„å€Ÿé‰´æ„ä¹‰ã€æ³¨æ„äº‹é¡¹ï¼‰\\n\\n## ğŸ”® è¶‹åŠ¿æ´å¯Ÿ\\nï¼ˆç›¸å…³æ¸¸æˆ/ç¡¬ä»¶çš„å‘å±•è¶‹åŠ¿ã€æ½œåœ¨å½±å“ï¼‰"
}}

**åˆ†æè¦æ±‚**ï¼š
1. title_cnè¦ç®€æ´ä¸“ä¸šï¼Œå»é™¤emojiå’Œè¿‡åº¦ä¿®é¥°
2. æ ¸å¿ƒè®®é¢˜è¦å‡†ç¡®æŠ“ä½å¸–å­çš„æœ¬è´¨
3. key_infoè¦æç‚¼æœ€æœ‰ä»·å€¼çš„3ä¸ªå…³é”®ç‚¹
4. post_typeè¦æ ¹æ®å†…å®¹å‡†ç¡®åˆ†ç±»
5. value_assessmentè¦å®¢è§‚è¯„ä¼°å¯¹ç©å®¶çš„ä»·å€¼
6. detailed_analysiså¿…é¡»åŒ…å«å®Œæ•´çš„6ä¸ªç»´åº¦ï¼Œæ¯ä¸ªç»´åº¦2-3å¥è¯
"""
    
    # è°ƒè¯•æ—¥å¿—
    logger.debug(f"  â†’ Prompté•¿åº¦: {len(prompt)}å­—ç¬¦, è¯„è®ºåŒºé•¿åº¦: {len(comment_section)}å­—ç¬¦")
    
    try:
        response = requests.post(
            DEEPSEEK_API_URL,
            headers={
                "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
                "Content-Type": "application/json"
            },
            json={
                "model": "deepseek-chat",
                "messages": [
                    {
                        "role": "system", 
                        "content": "ä½ æ˜¯ä¸“ä¸šçš„æ¸¸æˆç¤¾åŒºå†…å®¹åˆ†æä¸“å®¶ï¼Œæ“…é•¿åˆ†ææ¸¸æˆæ”»ç•¥ã€èµ„è®¯ã€è®¨è®ºå’Œç¡¬ä»¶è¯„æµ‹ã€‚ä½ çš„åˆ†æå®¢è§‚ä¸“ä¸šï¼Œæ³¨é‡å®ç”¨ä»·å€¼ã€‚"
                    },
                    {
                        "role": "user", 
                        "content": prompt
                    }
                ],
                "temperature": 0.3,
                "max_tokens": 2000
            },
            timeout=60
        )
        
        if response.status_code == 200:
            result = response.json()
            content = result['choices'][0]['message']['content']
            json_match = re.search(r'\{[\s\S]*\}', content)
            if json_match:
                analysis = json.loads(json_match.group())
                logger.info(f"    âœ“ AIåˆ†æå®Œæˆ")
                time.sleep(AI_REQUEST_DELAY)
                return analysis
        else:
            logger.warning(f"    âœ— APIè¿”å›é”™è¯¯: {response.status_code}")
                
    except Exception as e:
        logger.warning(f"    âœ— AIåˆ†æå¤±è´¥: {e}")
    
    # è¿”å›é»˜è®¤åˆ†æ
    return {
        'title_cn': post.get('title', ''),
        'core_issue': post.get('summary', post['title'])[:100],
        'key_info': [post['title']],
        'post_type': 'æœªåˆ†ç±»',
        'value_assessment': 'ä¸­',
        'detailed_analysis': f"## ğŸ® å†…å®¹èƒŒæ™¯\n\n{post.get('summary', '')[:200]}\n\n## ğŸ’¡ æ ¸å¿ƒå†…å®¹\n\nå¾…AIåˆ†æè¡¥å……"
    }

# ========== æ•°æ®åº“å­˜å‚¨ ==========

async def save_to_database(posts_with_analysis: List[Dict]):
    """ä¿å­˜åˆ°PostgreSQL"""
    logger.info(f"\nğŸ’¾ ä¿å­˜æ•°æ®åˆ°æ•°æ®åº“...")
    
    if not DATABASE_URL:
        logger.error("âŒ æœªé…ç½®DATABASE_URL")
        return False
    
    db_url = DATABASE_URL.split('?')[0] if '?' in DATABASE_URL else DATABASE_URL
    
    try:
        conn = await asyncpg.connect(db_url)
        logger.info("  âœ“ æ•°æ®åº“è¿æ¥æˆåŠŸ")
        
        saved_posts = 0
        saved_comments = 0
        
        for post in posts_with_analysis:
            try:
                await conn.execute('''
                    INSERT INTO heybox_posts (
                        id, title, title_cn, url, author, cover_image,
                        content_summary, likes_count, comments_count,
                        core_issue, key_info, post_type,
                        value_assessment, detailed_analysis, timestamp
                    ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15)
                    ON CONFLICT (id) DO UPDATE SET
                        title_cn = $3,
                        likes_count = $8,
                        comments_count = $9,
                        timestamp = $15
                ''', 
                    post['id'], post['title'], post['analysis'].get('title_cn', post['title']),
                    post['url'], post.get('author'), None,
                    post.get('summary', '')[:1000], post['likes_count'],
                    post['comments_count'],
                    post['analysis']['core_issue'],
                    json.dumps(post['analysis']['key_info']),
                    post['analysis']['post_type'],
                    post['analysis']['value_assessment'],
                    post['analysis']['detailed_analysis'],
                    datetime.fromtimestamp(post.get('created_time', time.time()))
                )
                saved_posts += 1
                
                # ä¿å­˜è¯„è®º
                for comment in post.get('comments', []):
                    try:
                        await conn.execute('''
                            INSERT INTO heybox_comments (
                                id, post_id, author, content, likes_count,
                                created_at, parent_id, depth
                            ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
                            ON CONFLICT (id) DO NOTHING
                        ''',
                            comment['id'], post['id'], comment.get('author', ''),
                            comment.get('content', ''), comment.get('likes_count', 0),
                            datetime.fromtimestamp(comment.get('created_time', time.time())),
                            comment.get('parent_id'), comment.get('depth', 0)
                        )
                        saved_comments += 1
                    except Exception as e:
                        logger.warning(f"    ä¿å­˜è¯„è®ºå¤±è´¥: {e}")
                        
            except Exception as e:
                logger.warning(f"    ä¿å­˜å¸–å­å¤±è´¥ {post['id']}: {e}")
        
        await conn.close()
        logger.info(f"âœ… æ•°æ®ä¿å­˜å®Œæˆ: {saved_posts}ä¸ªå¸–å­, {saved_comments}æ¡è¯„è®º")
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“æ“ä½œå¤±è´¥: {e}")
        return False

# ========== ä¸»æµç¨‹ ==========

async def main():
    """ä¸»æ‰§è¡Œæµç¨‹"""
    logger.info("=" * 80)
    logger.info("ğŸ® å°é»‘ç›’Playwrightçˆ¬è™«å¯åŠ¨")
    logger.info(f"ğŸ“¦ ç‰ˆæœ¬: {__version__}")
    logger.info(f"ğŸ• æ›´æ–°æ—¶é—´: {__update_date__}")
    logger.info("=" * 80)
    
    # æ£€æŸ¥é…ç½®
    issues = check_config()
    if issues:
        logger.error("\né…ç½®é—®é¢˜ï¼š")
        for issue in issues:
            logger.error(f"  {issue}")
        return
    
    logger.info(f"\né…ç½®ä¿¡æ¯ï¼š")
    logger.info(f"  - ç›®æ ‡å¸–å­æ•°: {POST_LIMIT}")
    logger.info(f"  - Tokenå·²é…ç½®: æ˜¯")
    logger.info(f"  - AIåˆ†æ: {'æ˜¯' if DEEPSEEK_API_KEY else 'å¦'}")
    logger.info(f"  - ä½¿ç”¨ä»£ç†: {'æ˜¯' if USE_PROXY else 'å¦'}")
    
    async with async_playwright() as p:
        # å¯åŠ¨æµè§ˆå™¨
        launch_options = {
            "headless": True,
            "args": ['--no-sandbox', '--disable-dev-shm-usage']
        }
        
        if USE_PROXY:
            proxies = get_proxies()
            if proxies and proxies.get('http'):
                launch_options["proxy"] = {"server": proxies['http']}
        
        browser = await p.chromium.launch(**launch_options)
        logger.info("âœ“ æµè§ˆå™¨å¯åŠ¨æˆåŠŸ")
        
        # åˆ›å»ºä¸Šä¸‹æ–‡ï¼ˆåçˆ¬è™«è®¾ç½®ï¼‰
        context = await browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            extra_http_headers={
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
                "Accept-Language": "zh-CN,zh;q=0.9",
            }
        )
        
        # åœ¨è®¿é—®é¡µé¢å‰é¢„å…ˆè®¾ç½®Cookieï¼Œç¡®ä¿é¦–æ¬¡è¯·æ±‚å³æºå¸¦è®¤è¯ä¿¡æ¯
        cookies_to_add = []
        if HEYBOX_TOKEN_ID:
            cookies_to_add.append({
                'name': 'x_xhh_tokenid',
                'value': HEYBOX_TOKEN_ID,
                'domain': '.xiaoheihe.cn',
                'path': '/',
                'httpOnly': False,
                'secure': True,
                'sameSite': 'Lax'
            })
        if HEYBOX_USER_PKEY:
            cookies_to_add.append({
                'name': 'user_pkey',
                'value': HEYBOX_USER_PKEY,
                'domain': '.xiaoheihe.cn',
                'path': '/',
                'httpOnly': False,
                'secure': True,
                'sameSite': 'Lax'
            })
            logger.info(f"âœ“ user_pkeyå·²é…ç½®ï¼ˆé•¿åº¦: {len(HEYBOX_USER_PKEY)}å­—ç¬¦ï¼‰")
        else:
            logger.warning("âš  user_pkeyæœªé…ç½®ï¼Œå¯èƒ½æ— æ³•è·å–ä¸ªæ€§åŒ–å†…å®¹")
        
        if cookies_to_add:
            await context.add_cookies(cookies_to_add)
            logger.info(f"âœ“ Cookieå·²é¢„å…ˆè®¾ç½®ï¼ˆ{len(cookies_to_add)}ä¸ªCookieï¼Œç¡®ä¿é¦–æ¬¡è¯·æ±‚æºå¸¦è®¤è¯ï¼‰")
        
        page = await context.new_page()
        
        # åº”ç”¨åçˆ¬è™«stealthï¼ˆå·²ç¦ç”¨ï¼štokenè®¤è¯å·²è¶³å¤Ÿï¼‰
        # await stealth(page)
        logger.info("âœ“ é¡µé¢åˆ›å»ºæˆåŠŸï¼ˆä½¿ç”¨Tokenè®¤è¯ï¼Œæ— éœ€stealthï¼‰")
        
        # ========== å¯¹æ¯”éªŒè¯ï¼šå…ˆè·å–é€šç”¨é¦–é¡µå†…å®¹ ==========
        logger.info("\n" + "="*80)
        logger.info("ğŸ” æ­¥éª¤0ï¼šè·å–é€šç”¨é¦–é¡µå†…å®¹ï¼ˆç”¨äºå¯¹æ¯”éªŒè¯ï¼‰")
        logger.info("="*80)
        
        # åˆ›å»ºæ–°é¡µé¢ï¼Œä¸è®¾ç½®Cookieï¼Œè®¿é—®é€šç”¨é¦–é¡µ
        page_no_auth = await context.new_page()
        await page_no_auth.goto(HEYBOX_HOME_URL, wait_until='networkidle', timeout=60000)
        await asyncio.sleep(5)  # ç­‰å¾…å†…å®¹åŠ è½½
        
        # æå–é€šç”¨é¦–é¡µçš„å¸–å­
        posts_no_auth = await extract_posts_from_page(page_no_auth, POST_LIMIT, "é€šç”¨é¦–é¡µ")
        await page_no_auth.close()
        
        if posts_no_auth:
            logger.info(f"âœ“ é€šç”¨é¦–é¡µæå–åˆ° {len(posts_no_auth)} ä¸ªå¸–å­")
            # è®°å½•é€šç”¨é¦–é¡µçš„å¸–å­IDå’Œæ ‡é¢˜
            general_post_ids = {post['id'] for post in posts_no_auth}
            logger.info(f"  é€šç”¨é¦–é¡µå¸–å­ID: {sorted(general_post_ids)}")
            logger.info(f"  é€šç”¨é¦–é¡µå¸–å­è¯¦æƒ…:")
            for i, post in enumerate(posts_no_auth, 1):
                logger.info(f"    {i}. [{post['id']}] {post['title'][:60]}")
        else:
            logger.warning("âš  æœªèƒ½è·å–é€šç”¨é¦–é¡µå†…å®¹")
            general_post_ids = set()
        
        # ========== è·å–ä¸ªæ€§åŒ–é¦–é¡µå†…å®¹ ==========
        logger.info("\n" + "="*80)
        logger.info("ğŸ” æ­¥éª¤1ï¼šè·å–ä¸ªæ€§åŒ–é¦–é¡µå†…å®¹")
        logger.info("="*80)
        
        # åˆå§‹åŒ–å¹¶æ³¨å…¥Token
        if not await init_browser_with_token(page, HEYBOX_TOKEN_ID):
            logger.error("âŒ åˆå§‹åŒ–å¤±è´¥")
            await browser.close()
            return
        
        # æå–ä¸ªæ€§åŒ–é¦–é¡µçš„å¸–å­
        posts = await extract_posts_from_page(page, POST_LIMIT, "ä¸ªæ€§åŒ–é¦–é¡µ")
        if not posts:
            logger.error("âŒ æœªèƒ½æå–å¸–å­æ•°æ®")
            await browser.close()
            return
        
        # ========== å¯¹æ¯”åˆ†æ ==========
        logger.info("\n" + "="*80)
        logger.info("ğŸ“Š å¯¹æ¯”åˆ†æï¼šåˆ¤æ–­æ˜¯å¦è·å–åˆ°ä¸ªæ€§åŒ–å†…å®¹")
        logger.info("="*80)
        
        personalized_post_ids = {post['id'] for post in posts}
        
        # è®¡ç®—å·®å¼‚
        unique_to_personalized = personalized_post_ids - general_post_ids
        unique_to_general = general_post_ids - personalized_post_ids
        common_posts = personalized_post_ids & general_post_ids
        
        logger.info(f"  ä¸ªæ€§åŒ–é¦–é¡µå¸–å­æ•°: {len(personalized_post_ids)}")
        logger.info(f"  é€šç”¨é¦–é¡µå¸–å­æ•°: {len(general_post_ids)}")
        logger.info(f"  å…±åŒå¸–å­æ•°: {len(common_posts)}")
        logger.info(f"  ä¸ªæ€§åŒ–ç‹¬æœ‰å¸–å­æ•°: {len(unique_to_personalized)}")
        logger.info(f"  é€šç”¨ç‹¬æœ‰å¸–å­æ•°: {len(unique_to_general)}")
        
        # åˆ¤æ–­æ˜¯å¦ä¸ªæ€§åŒ–
        if len(unique_to_personalized) > 0:
            similarity = len(common_posts) / max(len(personalized_post_ids), 1) * 100
            logger.info(f"  å†…å®¹ç›¸ä¼¼åº¦: {similarity:.1f}%")
            
            if similarity < 50:  # å¦‚æœç›¸ä¼¼åº¦ä½äº50%ï¼Œè®¤ä¸ºæ˜¯ä¸ªæ€§åŒ–å†…å®¹
                logger.info("  âœ… åˆ¤æ–­ï¼šå·²è·å–åˆ°ä¸ªæ€§åŒ–å†…å®¹ï¼ˆå†…å®¹å·®å¼‚è¾ƒå¤§ï¼‰")
                logger.info(f"  ä¸ªæ€§åŒ–ç‹¬æœ‰å¸–å­IDç¤ºä¾‹: {sorted(unique_to_personalized)[:3]}")
            elif len(unique_to_personalized) >= 3:
                logger.info("  âœ… åˆ¤æ–­ï¼šå·²è·å–åˆ°ä¸ªæ€§åŒ–å†…å®¹ï¼ˆæœ‰è¶³å¤Ÿå¤šçš„ç‹¬ç‰¹å¸–å­ï¼‰")
                logger.info(f"  ä¸ªæ€§åŒ–ç‹¬æœ‰å¸–å­IDç¤ºä¾‹: {sorted(unique_to_personalized)[:3]}")
            else:
                logger.warning("  âš  åˆ¤æ–­ï¼šå¯èƒ½æœªè·å–åˆ°ä¸ªæ€§åŒ–å†…å®¹ï¼ˆå†…å®¹ç›¸ä¼¼åº¦è¾ƒé«˜ï¼‰")
                logger.warning("  ğŸ’¡ å»ºè®®ï¼šæ£€æŸ¥user_pkeyæ˜¯å¦æ­£ç¡®ï¼Œæˆ–å¢åŠ ç­‰å¾…æ—¶é—´")
        else:
            logger.warning("  âŒ åˆ¤æ–­ï¼šæœªè·å–åˆ°ä¸ªæ€§åŒ–å†…å®¹ï¼ˆä¸é€šç”¨é¦–é¡µå®Œå…¨ç›¸åŒï¼‰")
            logger.warning("  ğŸ’¡ å»ºè®®ï¼šæ£€æŸ¥user_pkeyé…ç½®å’ŒCookieè®¾ç½®")
        
        logger.info("="*80 + "\n")
        
        logger.info(f"\nç¬¬1æ­¥å®Œæˆï¼šæå–åˆ° {len(posts)} ä¸ªå¸–å­\n")
        
        # æå–è¯„è®º
        for i, post in enumerate(posts, 1):
            logger.info(f"[{i}/{len(posts)}] å¤„ç†: {post['title'][:40]}")
            
            # è·å–è¯„è®º
            comments = await extract_comments(page, post['id'], post['url'])
            post['comments'] = comments
            
            await asyncio.sleep(REQUEST_INTERVAL)
        
        logger.info(f"\nç¬¬2æ­¥å®Œæˆï¼šè·å–è¯„è®º\n")
        
        # AIåˆ†æ
        logger.info("å¼€å§‹AIåˆ†æ...")
        for i, post in enumerate(posts, 1):
            logger.info(f"[{i}/{len(posts)}] åˆ†æ: {post['title'][:40]}")
            analysis = analyze_with_ai(post, post.get('comments', []))
            post['analysis'] = analysis
        
        logger.info(f"\nç¬¬3æ­¥å®Œæˆï¼šAIåˆ†æ\n")
        
        # ä¿å­˜æ•°æ®åº“ï¼ˆå¯¹æ ‡Reddit - ä»…æ•°æ®åº“ï¼Œä¸ç”ŸæˆJSONæ–‡ä»¶ï¼‰
        await save_to_database(posts)
        
        logger.info(f"âœ… æ•°æ®å·²å­˜å…¥æ•°æ®åº“ï¼Œå‰ç«¯å°†ä»æ•°æ®åº“è¯»å–")
        
        # å…³é—­æµè§ˆå™¨
        await browser.close()
    
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ‰ çˆ¬è™«æ‰§è¡Œå®Œæˆï¼")
    logger.info("=" * 80)

if __name__ == "__main__":
    asyncio.run(main())

